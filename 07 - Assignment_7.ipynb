{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbqYP0r2dh5mfrShOtVJg2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1\n",
        "Write a program to input three sentences from user and creates the corpus\n",
        "\n",
        "Example:\n",
        "\n",
        "Let’s say these 3 are your strings:\n",
        "\n",
        "S1=” India won the match”\n",
        "\n",
        "S2=” England won the cricket match”\n",
        "\n",
        "S3=” Australia won the final match”\n",
        "\n",
        "Then Corpus (list of union of all words from all strings) is:\n",
        "\n",
        "[India, England, Australia, won, the, match, cricket, final]\n",
        "\n",
        "\n",
        "Create a function named “MakeCorpus” which will take list of string as an input and will return a list having union of all\n",
        "words. Save this function in a python file named\n",
        "“Corpus”. This can be used for future applications"
      ],
      "metadata": {
        "id": "OL_m3Cd8i0Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-10nXdsjJFb",
        "outputId": "e30b4af7-8949-4afd-8a79-8bc827078d7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corp = set()\n",
        "def MakeCorpus(*args):\n",
        "  for sent in args:\n",
        "    for tok in word_tokenize(sent):\n",
        "      corp.add(tok)\n",
        "  return list(corp)\n",
        "\n",
        "S1='India won the match'\n",
        "\n",
        "S2='England won the cricket match'\n",
        "\n",
        "S3='Australia won the final match'\n",
        "\n",
        "MakeCorpus(S1, S2, S3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgbWDc5djkY3",
        "outputId": "6eda2f69-5034-44a6-f0af-0b79df609c11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'cricket', 'England', 'India', 'won', 'match', 'Australia', 'final']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Write a program to input three sentences from user and convert them into vectors.\n",
        "\n",
        "Use presence and absence of words to build the vectors.\n",
        "\n",
        "Example:\n",
        "Let's say these 3 are your strings:\n",
        "\n",
        "S1='India won the match'\n",
        "\n",
        "S2='England won the cricket match'\n",
        "\n",
        "S3='Australia won the final match'\n",
        "\n",
        "Then Corpus (list of union of all words from all strings) is:\n",
        "[India, England, Australia, won, the, match, cricket, final]\n",
        "\n",
        "So,\n",
        "\n",
        "S1 will be  [1,0,0,1,1,1,0,0]\n",
        "\n",
        "S2 will be  [0,1,0,1,1,1,1,0]\n",
        "\n",
        "S3 will be  [0,0,1,1,1,1,0,1]\n",
        "\n",
        "Create a function\n",
        "named “PresenceAbsenceVectorization” which will take list of\n",
        "string as an input and will return a list of vectors. Save this function in a python file named “Vectorization”. This can be used for future applications"
      ],
      "metadata": {
        "id": "B5SozcANkbvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PresenceAbsenceVectorization(*args):\n",
        "  corp = MakeCorpus(*args)\n",
        "\n",
        "  vecs = []\n",
        "  print(corp)\n",
        "  for sent in args:\n",
        "    vec = [0]*len(corp)\n",
        "    for tok in word_tokenize(sent):\n",
        "      if tok in corp:\n",
        "        vec[corp.index(tok)] = 1\n",
        "    vecs.append(vec)\n",
        "  return vecs\n",
        "\n",
        "\n",
        "S1='India won the match'\n",
        "\n",
        "S2='England won the cricket match'\n",
        "\n",
        "S3='Australia won the final match'\n",
        "\n",
        "ll = PresenceAbsenceVectorization(S1, S2, S3)\n",
        "print()\n",
        "\n",
        "print(S1)\n",
        "print(ll[0])\n",
        "print()\n",
        "print(S2)\n",
        "print(ll[1])\n",
        "print()\n",
        "print(S3)\n",
        "print(ll[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFqTv-Blj84Z",
        "outputId": "7b0278e0-ad8c-403d-e735-7527bfa0e26e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'cricket', 'England', 'India', 'won', 'match', 'Australia', 'final']\n",
            "\n",
            "India won the match\n",
            "[1, 0, 0, 1, 1, 1, 0, 0]\n",
            "\n",
            "England won the cricket match\n",
            "[1, 1, 1, 0, 1, 1, 0, 0]\n",
            "\n",
            "Australia won the final match\n",
            "[1, 0, 0, 0, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Write a program to enter 3 strings from a user and vectorise\n",
        "them on basis of their counts.\n",
        "\n",
        "Example: Let's say these 3 are your strings:\n",
        "\n",
        "S1 = \"A lives with B.A plays with C\"\n",
        "S2 = \"B lives with C. B plays with D\"\n",
        "S3 = \"C lives with D.C plays with A\"\n",
        "\n",
        "Then Corpus (list of union of all words from all strings) is:\n",
        "\n",
        "[A, B, C, D,lives,with,plays]\n",
        "\n",
        "So, S1 will be  [2,1,1,0,1,2,1]\n",
        "\n",
        "S2 will be  [0,2,1,1,1,2,1]\n",
        "\n",
        "S3 will be  [1,0,2,1,1,2,1]\n",
        "\n",
        "Create a function named “CountVectorization” which will take list of string as an input and will return a list of vectors. Save this function in a python file named “Vectorization”. This can be used for future applications"
      ],
      "metadata": {
        "id": "JdI4RyzZwden"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def CountVectorization(*args):\n",
        "  corpus = []\n",
        "\n",
        "  for sent in args:\n",
        "    corpus.append(sent)\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "  print('FEATURES ARE', vectorizer.get_feature_names_out())\n",
        "  return  X.toarray()\n",
        "\n",
        "S1 = 'Arjun lives with Biswas. Arjun plays with Chaitanya'\n",
        "\n",
        "S2 = 'Biswas lives with Chaitanya. Biswas plays with Dheeraj'\n",
        "\n",
        "S3 = 'Chaitanya lives with Dheeraj. Chaitanya plays with Arjun'\n",
        "\n",
        "ll = CountVectorization(S1, S2, S3)\n",
        "\n",
        "print()\n",
        "print(S1)\n",
        "print(ll[0])\n",
        "print()\n",
        "print(S2)\n",
        "print(ll[1])\n",
        "print()\n",
        "print(S3)\n",
        "print(ll[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLasjajvvYs8",
        "outputId": "21c83f58-0f12-43be-c926-a7bf1b4b15d8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEATURES ARE ['arjun' 'biswas' 'chaitanya' 'dheeraj' 'lives' 'plays' 'with']\n",
            "\n",
            "Arjun lives with Biswas. Arjun plays with Chaitanya\n",
            "[2 1 1 0 1 1 2]\n",
            "\n",
            "Biswas lives with Chaitanya. Biswas plays with Dheeraj\n",
            "[0 2 1 1 1 1 2]\n",
            "\n",
            "Chaitanya lives with Dheeraj. Chaitanya plays with Arjun\n",
            "[1 0 2 1 1 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Write a program to input 3 strings but vectorise them using TF-IDF (Term Frequency and Inverse Document Frequency) and print the strings along with the vectors.\n",
        "\n",
        "Create a function named “TFIDFVectorization” which will take list\n",
        "of string as an input and will return a list of vectors.\n",
        "\n",
        "Save this function in a python file named\n",
        "“Vectorization”. This can be used for future applications"
      ],
      "metadata": {
        "id": "AFBUgUdJ40C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def TFIDFVectorization(*args):\n",
        "  corpus = []\n",
        "\n",
        "  for sent in args:\n",
        "    corpus.append(sent)\n",
        "\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "  print('FEATURES ARE', vectorizer.get_feature_names_out())\n",
        "  return  X.toarray()\n",
        "\n",
        "S1 = 'Arjun lives with Biswas. Arjun plays with Chaitanya'\n",
        "\n",
        "S2 = 'Biswas lives with Chaitanya. Biswas plays with Dheeraj'\n",
        "\n",
        "S3 = 'Chaitanya lives with Dheeraj. Chaitanya plays with Arjun'\n",
        "\n",
        "ll = TFIDFVectorization(S1, S2, S3)\n",
        "\n",
        "print()\n",
        "print(S1)\n",
        "print(ll[0])\n",
        "print()\n",
        "print(S2)\n",
        "print(ll[1])\n",
        "print()\n",
        "print(S3)\n",
        "print(ll[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjRJZQepynxq",
        "outputId": "1cd3bd2c-ccfc-41b8-929f-1805ba6aa82c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEATURES ARE ['arjun' 'biswas' 'chaitanya' 'dheeraj' 'lives' 'plays' 'with']\n",
            "\n",
            "Arjun lives with Biswas. Arjun plays with Chaitanya\n",
            "[0.65860651 0.32930325 0.25573335 0.         0.25573335 0.25573335\n",
            " 0.51146671]\n",
            "\n",
            "Biswas lives with Chaitanya. Biswas plays with Dheeraj\n",
            "[0.         0.65860651 0.25573335 0.32930325 0.25573335 0.25573335\n",
            " 0.51146671]\n",
            "\n",
            "Chaitanya lives with Dheeraj. Chaitanya plays with Arjun\n",
            "[0.35287239 0.         0.54807377 0.35287239 0.27403689 0.27403689\n",
            " 0.54807377]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DnM35quS5dpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}